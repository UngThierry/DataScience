{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IA & Data science (LU3IN026) -- 2020-2021\n",
    "--------\n",
    "*&copy; Equipe pédagogique: Vincent Guigue, Christophe Marsala, Edoardo Sarti, Olivier Schwander.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projet 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation du notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"RED\">**[Q]**</font> **Indiquer dans la boîte ci-dessous vos noms et prénoms :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ung Thierry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> **Renommer ce fichier ipython**\n",
    "\n",
    "Tout en haut de cette page, cliquer sur <tt>projet-2021</tt> et rajouter à la suite de <tt>projet-2021</tt> les noms des membres du binômes séparés par un tiret.\n",
    "\n",
    "Par exemple, pour le binôme Luke Skywalker et Han Solo, le nom de fichier devient `projet2021-Skywalker-Solo`\n",
    "\n",
    "Penser à sauvegarder fréquemment le fichier en cours de travail :\n",
    "- soit en cliquant sur l'icône \"disquette\"\n",
    "- soit par la combinaison de touches [Ctrl]-S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données\n",
    "\n",
    "Les données vous sont fournies sur le moodle. \n",
    "Ces données sont fournies sur Kaggle, ce sont les données *Google Play Store Apps* accessibles à l'adresse https://www.kaggle.com/lava18/google-play-store-apps.\n",
    "\n",
    "Il est indispensable de lire en détail la page Kaggle pour comprendre à quoi ces données correspondent.\n",
    "\n",
    "Le compte-rendu a fournir le jour de la dernière séance de TDTME de votre groupe doit comporter:\n",
    "- un fichier PDF qui correspond à un poster sur lequel sont expliqués les différents problèmes traités, la façon dont ils ont été traités, et les résultats obtenus.\n",
    "- un notebook par problème traité, vous pouvez traiter autant de problème que vous le souhaitez. Le problème étudié doit être décrit précisément et vous devez impérativement suivre le format ci-dessous.\n",
    "\n",
    "Bien entendu, le tout sera mis dans un fichier archive (tar.gz ou zip exclusivement) et déposé sur le site Moodle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Dans cette partie du notebook, on effectue tout les import de modules allant etre utilisés dans le projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des librairies standards :\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline  \n",
    "\n",
    "# Importation de votre librairie iads :\n",
    "# La ligne suivante permet de préciser le chemin d'accès à la librairie iads\n",
    "import sys\n",
    "sys.path.append('../') # iads doit être dans le répertoire frère du répertoire courant !\n",
    "\n",
    "# Importation de la librairie iads\n",
    "import iads as iads\n",
    "\n",
    "# importation de Classifiers\n",
    "from iads import Classifiers as cl\n",
    "\n",
    "# importation de utils\n",
    "from iads import utils as ut\n",
    "\n",
    "# commande TRES utile pour recharger automatiquement le code que vous modifiez dans les modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 0 - Chargement et nettoyage des données\n",
    "\n",
    "## Données Google Play Store\n",
    "\n",
    "Dans les données à analyser, il existe des exemples ne pouvant pas etre utilisés puisque certains champs de ces exemples sont inutilisables. \n",
    "Par exemple, il peut s'agir de champs Nan ou de valeurs anormales (dans le champ Size de certains exemples, on a parfois la valeur 'Varies with device'). \n",
    "Il faut donc retirer ces exemples de la base de données en priorité.\n",
    "\n",
    "On récupère les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf = pd.read_csv(\"data/GoogleApps/googleplaystore.csv\")\n",
    "gpsdf[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre d'exemples dans la base de données est de :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpsdf.shape[0], \"exemples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les différents champs des exemples de cette base de données sont :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in gpsdf.columns :\n",
    "    print(i)\n",
    "print(\"(\" + str(len(gpsdf.columns)) + \" champs différents)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les informations relatives à chacun des champs de la base de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que les champs Rating, Type, Content Rating, Current Ver ou Android Ver de certains exemples sont nuls. Il faut donc retirer ces exemples en priorité.\n",
    "\n",
    "On s'occupe dans un premier temps de retirer toutes les exemples possedant des champs avec des valeurs Nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf = gpsdf.dropna()\n",
    "gpsdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre d'exemples dans la base de données est maintenant de 9360 exemples.\n",
    "\n",
    "La fonction suivante permet de retirer le prefixe, le suffixe et d'autres éléments inutiles dans les champs des exemples de la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_elements(column) :\n",
    "    \"\"\" La fonction prend en argument une colonne de la base de données et la renvoie nettoyée\n",
    "    \"\"\"\n",
    "    column = column.str.replace('+', '') # Suppression des symboles +\n",
    "    column = column.str.replace(',', '') # Suppression des symboles ,\n",
    "    column = column.str.replace('$', '') # Suppression des symboles $\n",
    "    column = column.str.replace(\"'\", '') # Suppression des symboles '\n",
    "    \n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage de la colonne Category\n",
    "\n",
    "On affiche les valeurs unique de la colonne Category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpsdf.loc[:,'Category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin que ces valeurs soient utilisables lors de l'apprentissage, on décide de diviser la colonne 'Category' en plusieurs colonnes différents. \n",
    "<br/>Chaque colonne permettra de savoir à quelle catégorie de 'Category' cette application appartient. \n",
    "<br/>(Par exemple, si une application a la valeur 1 dans son champ 'Category_GAME', cela signifie que l'application est destinée fait partie de la catégorie 'GAME')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf = pd.concat([gpsdf, pd.get_dummies(gpsdf['Category'], prefix='C')], axis=1)\n",
    "gpsdf.drop(['Category'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche l'état de la base de données après avoir réalisé la modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage de la colonne Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les valeurs uniques de la colonne Rating. Il s'agit de flottants donc ces valeurs peut etre directement utilisées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf.loc[:,'Rating'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage de la colonne Reviews\n",
    "\n",
    "On affiche les valeurs uniques de la colonne Reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf.loc[:,'Reviews'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On souhaite également transformer les valeurs de Reviews en entier afin de faciliter leurs utilisations lors de l'apprentissage (elles sont pour l'instant au format String).\n",
    "<br/>On utilise pour cela la fonction to_numeric de la bibliothèque pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf['Reviews'] = pd.to_numeric(gpsdf['Reviews'])\n",
    "gpsdf.loc[:,'Reviews'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage de la colonne Size\n",
    "\n",
    "On affiche les valeurs uniques de la colonne Size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpsdf.loc[:,'Size'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La valeur 'Varies with device' ne pouvant pas etre utilisée lors de l'apprentissage, on décide de supprime tout les exemples de la base de données dont la valeur du champ Size est 'Varies with device'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf.drop(gpsdf[gpsdf['Size'] == \"Varies with device\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre d'exemples dans la base de données est désormais de :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpsdf.shape[0], \"exemples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On aimerait que ces valeurs soit des flottants et non pas des String. On suppose que les 'M' représente les mega-octets et 'k' les kilo-octets.\n",
    "<br/>On effectue alors une modification générale sur tout les champs Size des exemples de la base de données. <br/>On décide de garder comme valeur la taille en mega-octets de l'application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_data = gpsdf['Size'].loc[gpsdf['Size'].str.contains('k')].index.tolist()\n",
    "convert_data = pd.DataFrame(gpsdf.loc[size_data, 'Size'].apply(lambda x : x.strip('k')).astype(float).apply(lambda x : x/1024).apply(lambda x : round(x, 3)).astype(str))\n",
    "gpsdf.loc[size_data, 'Size'] = convert_data\n",
    "\n",
    "gpsdf['Size'] = gpsdf['Size'].apply(lambda x:x.strip('M'))\n",
    "gpsdf['Size'] = gpsdf['Size'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les valeurs uniques de la colonne Size après modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpsdf.loc[:,'Size'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage de la colonne Installs\n",
    "\n",
    "Dans la colonne Installs, les données sont représentées sous la forme \"valeur\"+ et la valeur est parfois séparée par des virgules. On préfère garder uniquement la valeur et retirer le symbole +. On fait donc appel à la fonction remove_elements sur la colonne.\n",
    "\n",
    "Les éléments uniques de la colonne Installs avant l'utilisation de la fonction sont :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf.loc[:,'Installs'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf['Installs'] = clean_elements(gpsdf['Installs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les éléments uniques de la colonne Installs après l'utilisation de la fonction sont :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf.loc[:,'Installs'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On souhaite également transformer les valeurs de Installs en entier afin de faciliter leurs utilisations lors de l'apprentissage (elles sont pour l'instant au format String).\n",
    "<br/>On utilise pour cela la fonction to_numeric de la bibliothèque pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf['Installs'] = pd.to_numeric(gpsdf['Installs'])\n",
    "gpsdf.loc[:,'Installs'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage de la colonne Type\n",
    "\n",
    "On affiche les valeurs uniques de la colonne Type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf.loc[:,'Type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin que ces données soient utilisables lors de l'apprentissage, on décide de représenter la valeur 'Free' par la valeur 0 et la valeur 'Paid' par la valeur 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf.loc[:,'Type'] = gpsdf.loc[:,'Type'].apply(lambda x : 0 if (x == 'Free') else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les valeurs uniques de la colonne Type après modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf.loc[:,'Type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage de la colonne Price\n",
    "\n",
    "On affiche les valeurs uniques de la colonne Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpsdf.loc[:,'Price'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin que ces valeurs soient utilisables lors de l'apprentissage, on décide de retirer les symboles '$' et de les convertir en flottant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf['Price'] = clean_elements(gpsdf['Price'])\n",
    "gpsdf['Price'] = pd.to_numeric(gpsdf['Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les valeurs uniques de la colonne Price après modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpsdf.loc[:,'Price'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage de la colonne Content Rating\n",
    "\n",
    "On affiche les valeurs uniques de la colonne Content Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf.loc[:,'Content Rating'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin que ces valeurs soient utilisables lors de l'apprentissage, on décide de diviser la colonne 'Content Rating' en plusieurs colonnes différents. \n",
    "<br/>Chaque colonne permettra de savoir à quelle catégorie de 'Content Rating' cette application appartient.\n",
    "<br/>(Par exemple, si une application a la valeur 1 dans son champ 'CR_Everyone', cela signifie que l'application est destinée à tout les public, soit 'Everyone')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsdf = pd.concat([gpsdf, pd.get_dummies(gpsdf['Content Rating'], prefix='CR')], axis=1)\n",
    "gpsdf.drop(['Content Rating'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage des colonnes Application, Genres, Last Updated, Current Ver et Android Ver\n",
    "\n",
    "Aucune modification ne sera effectuée au niveau de ces colonnes puisque leurs données ne seront pas utilisées lors de l'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche l'état de la base de données après avoir réalisé la modification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gpsdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les différentes colonnes de la base de données sont désormais :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in gpsdf.columns :\n",
    "    print(c)\n",
    "print(\"(\" + str(gpsdf.shape[1]) + \" champs différents)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données Google Play Store Reviews\n",
    "\n",
    "Comme pour la première base de données que nous allons utiliser, nous allons procéder au nettoyage de la deuxième afin que ces données soient utilisables lors de l'apprentissage.\n",
    "\n",
    "On récupère la base de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsrevdf = pd.read_csv(\"data/GoogleApps/googleplaystore_user_reviews.csv\")\n",
    "gpsrevdf[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre d'exemple dans la base de données est de :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(gpsrevdf.shape[0]) + \" exemples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les différentes champs des exemples de la base de données sont :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in gpsrevdf.columns :\n",
    "    print(c)\n",
    "print(\"(\" + str(gpsrevdf.shape[1]) + \" champs différents)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les informations de la base de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsrevdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que les champs Translated_Review, Sentiment, Sentiment_Polarity ou Sentiment_Subjectivity de certains exemples sont nuls. Il faut donc retirer ces exemples en priorité.\n",
    "\n",
    "On s'occupe dans un premier temps de retirer toutes les exemples possedant des champs avec des valeurs Nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpsrevdf = gpsrevdf.dropna()\n",
    "gpsrevdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre d'exemples dans la base de données est désormais de 37427 exemples.\n",
    "\n",
    "On compte dans cette base de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"- \" + str(len(gpsrevdf[gpsrevdf['Sentiment'] == 'Positive'])) + \" revues positives\")\n",
    "print(\"- \" + str(len(gpsrevdf[gpsrevdf['Sentiment'] == 'Neutral'])) + \" revues sans sentiments particuliers\")\n",
    "print(\"- \" + str(len(gpsrevdf[gpsrevdf['Sentiment'] == 'Negative'])) + \" revues négatives\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Partie 1 - Description du problème\n",
    "\n",
    "Aujourd'hui, le téléphone portable est un appareil dont on ne peut plus se passer. Elles peuvent remplir un nombre illimité de fonctions. Afin de remplir ces fonctions, des applications sont développées et sont à télécharger sur des marchés d'applications (GooglePlayStore pour les produits Android, ...).\n",
    "\n",
    "On va voir quels sont les facteurs qui permette de prédire la popularité d'une application mobile ? Est-ce que le fait qu'une application soit payante ou non puisse empêcher la prédiction de sa popularité ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 - Modèle\n",
    "\n",
    "Le modèle utilisé afin de répondre à la problématique est le classifieur k-means.\n",
    "\n",
    "La particularité de ce modèle est de regrouper les exemples d'une base de données au sein de clusters. Les clusters sont des ensembles d'exemples situés autour d'un centroïde.\n",
    "\n",
    "À l'initialisation, les centroïdes sont des exemples tirés de la base de données d'apprentissage et on définit les premiers clusters. Puis à chaque itération durant n itérations, on met à jour les clusters et un dictionnaire d'appartenance. Ce dictionnaire d'appartenance permet de savoir à quel cluster chaque exemple appartient. Il est important de noter qu'un exemple ne peut appartenir qu'à un seul et unique cluster.\n",
    "\n",
    "Après avoir réalisé l'apprentissage sur un certain nombre d'itérations, on obtient alors un ensemble de clusters fixes. On peut alors prédire des exemples grace au modèle. Comme on a pas eu à définir une méthode de prédiction précise lors du TME8, on a décidé de notre propre méthode de prédiction.\n",
    "\n",
    "La prédiction d'un exemple est réalisée de la manière suivante :\n",
    "- on place l'exemple à prédire dans nos données\n",
    "- on trouve à quel cluster il appartient\n",
    "- on récupère les points faisant partie de ce cluster grace au dictionnaire d'appartenance\n",
    "- on renvoie le label le plus représenté dans le cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3 - Code\n",
    "\n",
    "### Mise en place de l'algorithme d'apprentissage\n",
    "\n",
    "Le code du classifieur utilisant cet algorithme pour son apprentissage est le suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toutes les fonctions liées à ce classifieur ont été mises en place dans le fichier utils.py du package iads\n",
    "class ClassifierKmeans(cl.Classifier):\n",
    "    \"\"\" Classe pour représenter un classifieur linéaire aléatoire\n",
    "        Cette classe hérite de la classe Classifier\n",
    "    \"\"\"\n",
    "    def __init__(self, nbCentroides):\n",
    "        \"\"\" Constructeur de Classifier\n",
    "            Argument:\n",
    "                - intput_dimension (int) : dimension de la description des exemples\n",
    "            Hypothèse : input_dimension > 0\n",
    "        \"\"\"\n",
    "        self.nbCentroides = nbCentroides\n",
    "        self.desc_set = []\n",
    "        self.label_set = []\n",
    "        self.liste_centroides = []\n",
    "        self.matrice_affectation = []\n",
    "        \n",
    "    def train(self, desc_set, label_set, epsilon=0.01, itermax=1000):\n",
    "        \"\"\" Permet d'entrainer le modele sur l'ensemble donné\n",
    "            desc_set: ndarray avec des descriptions\n",
    "            label_set: ndarray avec les labels correspondants\n",
    "            Hypothèse: desc_set et label_set ont le même nombre de lignes\n",
    "        \"\"\"\n",
    "        self.desc_set = desc_set\n",
    "        self.label_set = label_set\n",
    "        # Utilisation de l'algorithme des k-means\n",
    "        (centroides, affectation) = ut.kmoyennes(self.nbCentroides, self.desc_set, epsilon, itermax)\n",
    "        self.liste_centroides = centroides\n",
    "        self.matrice_affectation = affectation\n",
    "            \n",
    "    def score(self,x):\n",
    "        \"\"\" renvoie un dictionnaire de prédiction sur x (valeur réelle)\n",
    "            x: une description\n",
    "        \"\"\"\n",
    "        id_centroide = ut.plus_proche(x, self.liste_centroides)\n",
    "        liste_attr = self.matrice_affectation[id_centroide]\n",
    "        \n",
    "        # On effectue le compte sur les labels présents dans la liste\n",
    "        compte_label = dict()\n",
    "        for p in liste_attr :\n",
    "            if (self.label_set[p] not in compte_label.keys()) :\n",
    "                compte_label[self.label_set[p]] = 1 \n",
    "            else :\n",
    "                compte_label[self.label_set[p]] += 1 \n",
    "\n",
    "        return compte_label\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\" rend la prediction sur x (soit -1 ou soit +1)\n",
    "            x: une description\n",
    "        \"\"\"\n",
    "        dict_prediction = self.score(x)\n",
    "        keys_dict = list(dict_prediction.keys())\n",
    "        \n",
    "        # On cherche le label le plus présent dans le cluster associé à la description x\n",
    "        prediction = keys_dict[0]\n",
    "        for k in keys_dict :\n",
    "            if (dict_prediction[prediction] < dict_prediction[k]) :\n",
    "                prediction = k\n",
    "                \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des données\n",
    "\n",
    "Grâce à la libraire Seaborn (importée sous le nom 'sns'), on peut avoir une idée de l'état des bases de données que nous allons utiliser.\n",
    "\n",
    "On affiche dans un premier temps les données importantes de la première base de données, soit gpsdf, en faisait la séparation entre les données concernant les applications payantes et les applications gratuites.\n",
    "\n",
    "On considère que les données principales de cette base de données sont :\n",
    "- Rating\n",
    "- Size\n",
    "- Installs\n",
    "- Reviews\n",
    "- Type\n",
    "- Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# On récupère les données importantes de la base de données gpsdf\n",
    "rating_data = gpsdf['Rating']\n",
    "size_data = gpsdf['Size']\n",
    "installs_data = gpsdf['Installs']\n",
    "reviews_data = gpsdf['Reviews']\n",
    "type_data = gpsdf['Type']\n",
    "price_data = gpsdf['Price']\n",
    "\n",
    "# Affichage des données\n",
    "plotgrap = sns.pairplot(pd.DataFrame(list(zip(rating_data, size_data, np.log(installs_data), np.log(reviews_data), type_data, price_data)), columns=['Rating', 'Size', 'Installs', 'Reviews', 'Type', 'Price']), hue='Type', palette=\"Set1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rappel de la signification des valeurs de Type :\n",
    "- 0 = Free\n",
    "- 1 = Paid\n",
    "\n",
    "On affiche désormais les données importantes de la deuxième base de données, soit gpsrevdf, en faisait la séparation entre les données concernant les revues positives et negatives.\n",
    "\n",
    "On considère que les données principales de cette base de données sont :\n",
    "- Sentiment\n",
    "- Sentiment_Polarity\n",
    "- Sentiment_Subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère les données importantes de la base de données gpsrevdf \n",
    "sentiment_data = gpsrevdf['Sentiment']\n",
    "sent_pol_data = gpsrevdf['Sentiment_Polarity']\n",
    "sent_sub_data = gpsrevdf['Sentiment_Subjectivity']\n",
    "\n",
    "# Affichage des données\n",
    "plotgrap = sns.pairplot(pd.DataFrame(list(zip(sentiment_data, sent_pol_data, sent_sub_data)), columns=['Sentiment', 'Sentiment_Polarity', 'Sentiment_Subjectivity']), hue='Sentiment', palette=\"Set1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 4 - Protocole expérimental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le protocole expérimental est le suivant :\n",
    "\n",
    "#### Etape 1\n",
    "On met en place des modèles de prédiction basés le nombre de téléchargements (Installs) de chaque application de la base de données.\n",
    "<br/>Pour chaque apprentissage, la combinaison des paramètres utilisés, soit les dimensions utilisées pour classer les exemples, seront différentes.\n",
    "<br/>Afin de vérifier les résultats de chaque classifieur, on utilise une validation croisée.\n",
    "\n",
    "#### Etape 2\n",
    "On fait le même travail qu'à l'étape précédente, sauf que les modèles de prédiction seront cette fois-ci basés sur la note (Rating) de chaque application de la base de données.\n",
    "\n",
    "#### Etape 3\n",
    "On effectue une première analyse des résultats obtenus dans les étapes 1 et 2, soit les précisions de la validation croisée.\n",
    "<br/>On trouve quel modèle de prédiction est le plus prometteur en matière de résultats. Tous les modèles générés par la suite seront basés sur ce modèle.\n",
    "<br/>On effectue également une sélection des exemples dans la base de données. On retire les exemples que l'on considère comme \"inutiles\", soit les exemples n'ayant aucune valeur d'apprentissage à nos yeux, et on vérifie le nouvel état de la base de données.\n",
    "\n",
    "#### Etape 4\n",
    "On met en place de nouveaux modèles de prédiction en utilisant la nouvelle base de données créée à l'étape 3. Les résultats rendus par ces modèles doivent normalement être supérieurs à ceux obtenus dans les étapes précédentes puisque nous avons réalisé une sélection des exemples en ne conservant que les plus intéressants.\n",
    "\n",
    "#### Etape 5\n",
    "On récupère le modèle ayant réalisé les meilleures performances. On renouvelle alors l'apprentissage sur ce modèle sur plusieurs itérations avec un nombre de centroïdes différents à chaque itération. On compare par la suite les résultats obtenus et on conserve le nouveau modèle avec les meilleures performances.\n",
    "\n",
    "#### Etape 6\n",
    "On effectue une séparation de la base de données afin de pouvoir utiliser le modèle sur les applications payantes et les applications gratuites. On effectue une nouvelle série de tests avec les deux nouveaux ensembles de données.\n",
    "\n",
    "#### Remarque sur l'expérimentation\n",
    "Chaque fois que l'on doit mettre en place un nouveau modèle de prédiction, on crée dans un premier temps un modèle pilote, avec un important nombre de centroïde, dont on affichera la représentation graphique afin d'avoir une idée de la disposition des données et leur répartition au sein des clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 5 - Résultats\n",
    "\n",
    "## 1) Prédiction du nombre de téléchargements (Installs)\n",
    "\n",
    "Dans cette première partie des résultats, on va chercher à montrer s'il existe une combinaison de facteurs permettant une prédiction du nombre de téléchargements d'une application.\n",
    "<br/>Les facteurs allant être utilisés ici sont :\n",
    "- la note attribuée à l'application (Rating)\n",
    "- le nombre d'avis déposés par les utilisateurs (Reviews)\n",
    "- la taille en octets d'une application (Size)\n",
    "\n",
    "### Prédiction en fonction de Rating et Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Récupération des labels\n",
    "label_installs_set = gpsdf['Installs'].to_numpy()\n",
    "\n",
    "# Récupération des descriptions\n",
    "desc_rating_reviews_set = ut.normalisation(gpsdf[['Rating', 'Reviews']].to_numpy()) # Rating x Reviews\n",
    "\n",
    "# Création d'un classifieur k-means allant étudier la situation\n",
    "kmeans_rating_reviews = ClassifierKmeans(30)\n",
    "\n",
    "# Entrainement du classifieur\n",
    "kmeans_rating_reviews.train(desc_rating_reviews_set, label_installs_set, epsilon=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir réalisé l'apprentissage, on obtient les clusters suivants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.affiche_resultat(kmeans_rating_reviews.desc_set ,kmeans_rating_reviews.liste_centroides, kmeans_rating_reviews.matrice_affectation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(chaque couleur représente un cluster et chaque croix représente un centroide de cluster)\n",
    "\n",
    "En utilisant 50 clusters différents, on obtient les résultats de précision suivants grâce à la validation croisée sur 10 itérations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des données (Rating X Reviews => Installs)\n",
    "X = ut.normalisation(gpsdf[['Rating', 'Reviews']].to_numpy())\n",
    "Y = gpsdf['Installs'].to_numpy()\n",
    "\n",
    "niter = 10\n",
    "nbCentroides = 50\n",
    "perf = []\n",
    "# Utilisation de la validation croisée\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = ut.crossval(X, Y, niter, i)\n",
    "    cl = ClassifierKmeans(nbCentroides)\n",
    "    cl.train(Xapp, Yapp)\n",
    "    perf.append(cl.accuracy(Xtest, Ytest))\n",
    "    print(\"Apprentissage \",i+1,\":\\t\",\" |Yapp|= \",len(Yapp),\" |Ytest|= \",len(Ytest),\"\\tperf= \",perf[-1])\n",
    "\n",
    "# On transforme la liste en array numpy pour avoir les fonctions statistiques:\n",
    "perf = np.array(perf)\n",
    "print(f'\\nRésultat global avec crossval :\\tmoyenne= {perf.mean():.3f}\\técart-type= {perf.std():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction en fonction de Rating et Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des labels\n",
    "label_installs_set = gpsdf['Installs'].to_numpy()\n",
    "\n",
    "# Récupération des descriptions\n",
    "desc_rating_size_set = ut.normalisation(gpsdf[['Rating', 'Size']].to_numpy()) # Rating x Size\n",
    "\n",
    "# Création d'un classifieur k-means allant étudier la situation\n",
    "kmeans_rating_size = ClassifierKmeans(50)\n",
    "\n",
    "# Entrainement du classifieur\n",
    "kmeans_rating_size.train(desc_rating_size_set, label_installs_set, epsilon=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir réalisé l'apprentissage, on obtient les clusters suivants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.affiche_resultat(kmeans_rating_size.desc_set ,kmeans_rating_size.liste_centroides, kmeans_rating_size.matrice_affectation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant 50 clusters différents, on obtient les résultats de précision suivants grâce à la validation croisée sur 10 itérations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des données (Rating X Size => Installs)\n",
    "X = ut.normalisation(gpsdf[['Rating', 'Size']].to_numpy())\n",
    "Y = gpsdf['Installs'].to_numpy()\n",
    "\n",
    "niter = 10\n",
    "nbCentroides = 50\n",
    "perf = []\n",
    "# Utilisation de la validation croisée\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = ut.crossval(X, Y, niter, i)\n",
    "    cl = ClassifierKmeans(nbCentroides)\n",
    "    cl.train(Xapp, Yapp)\n",
    "    perf.append(cl.accuracy(Xtest, Ytest))\n",
    "    print(\"Apprentissage \",i+1,\":\\t\",\" |Yapp|= \",len(Yapp),\" |Ytest|= \",len(Ytest),\"\\tperf= \",perf[-1])\n",
    "\n",
    "# On transforme la liste en array numpy pour avoir les fonctions statistiques:\n",
    "perf = np.array(perf)\n",
    "print(f'\\nRésultat global avec crossval :\\tmoyenne= {perf.mean():.3f}\\técart-type= {perf.std():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction en fonction de Reviews et Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des labels\n",
    "label_installs_set = gpsdf['Installs'].to_numpy()\n",
    "\n",
    "# Récupération des descriptions\n",
    "desc_reviews_size_set = ut.normalisation(gpsdf[['Reviews', 'Size']].to_numpy()) # Rating x Size\n",
    "\n",
    "# Création d'un classifieur k-means allant étudier la situation\n",
    "kmeans_reviews_size = ClassifierKmeans(50)\n",
    "\n",
    "# Entrainement du classifieur\n",
    "kmeans_reviews_size.train(desc_reviews_size_set, label_installs_set, epsilon=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir réalisé un premier apprentissage, on obtient les clusteurs suivants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.affiche_resultat(kmeans_reviews_size.desc_set ,kmeans_reviews_size.liste_centroides, kmeans_reviews_size.matrice_affectation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant 50 clusters différents, on obtient les résultats de précision suivants grâce à la validation croisée sur 10 itérations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des données (Reviews X Size => Installs)\n",
    "X = ut.normalisation(gpsdf[['Reviews', 'Size']].to_numpy())\n",
    "Y = gpsdf['Installs'].to_numpy()\n",
    "\n",
    "niter = 10\n",
    "nbCentroides = 50\n",
    "perf = []\n",
    "# Utilisation de la validation croisée\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = ut.crossval(X, Y, niter, i)\n",
    "    cl = ClassifierKmeans(nbCentroides)\n",
    "    cl.train(Xapp, Yapp)\n",
    "    perf.append(cl.accuracy(Xtest, Ytest))\n",
    "    print(\"Apprentissage \",i+1,\":\\t\",\" |Yapp|= \",len(Yapp),\" |Ytest|= \",len(Ytest),\"\\tperf= \",perf[-1])\n",
    "\n",
    "# On transforme la liste en array numpy pour avoir les fonctions statistiques:\n",
    "perf = np.array(perf)\n",
    "print(f'\\nRésultat global avec crossval :\\tmoyenne= {perf.mean():.3f}\\técart-type= {perf.std():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Prédiction de la note de l'application (Rating)\n",
    "\n",
    "On s'intéresse désormais à la note moyenne donnée par les utilisateurs de l'application à cette dernière. On va chercher s'il existe une combinaison de facteurs permettant de pouvoir prédire la note d'une application.\n",
    "<br/>Les facteurs allant être étudiés dans cette partie sont :\n",
    "- le nombre de téléchargements de l'application (Installs)\n",
    "- le nombre d'avis déposés par les utilisateurs (Reviews)\n",
    "- la taille en octets d'une application (Size)\n",
    "\n",
    "### Prédiction en fonction de Installs et Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des labels\n",
    "label_rating_set = gpsdf['Rating'].to_numpy()\n",
    "\n",
    "# Récupération des descriptions\n",
    "desc_installs_reviews_set = ut.normalisation(gpsdf[['Installs', 'Reviews']].to_numpy()) # Installs x Reviews\n",
    "\n",
    "# Création d'un classifieur k-means allant étudier la situation\n",
    "kmeans_installs_reviews = ClassifierKmeans(50)\n",
    "\n",
    "# Entrainement du classifieur\n",
    "kmeans_installs_reviews.train(desc_installs_reviews_set, label_rating_set, epsilon=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir réalisé un premier apprentissage, on obtient les clusters suivants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ut.affiche_resultat(kmeans_installs_reviews.desc_set, kmeans_installs_reviews.liste_centroides, kmeans_installs_reviews.matrice_affectation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant 50 clusters différents, on obtient les résultats de précision suivants grâce à la validation croisée sur 10 itérations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des données (Installs X Reviews => Rating)\n",
    "X = ut.normalisation(gpsdf[['Installs', 'Reviews']].to_numpy())\n",
    "Y = gpsdf['Rating'].to_numpy()\n",
    "\n",
    "niter = 10\n",
    "nbCentroides = 50\n",
    "perf = []\n",
    "# Utilisation de la validation croisée\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = ut.crossval(X, Y, niter, i)\n",
    "    cl = ClassifierKmeans(nbCentroides)\n",
    "    cl.train(Xapp, Yapp)\n",
    "    perf.append(cl.accuracy(Xtest, Ytest))\n",
    "    print(\"Apprentissage \",i+1,\":\\t\",\" |Yapp|= \",len(Yapp),\" |Ytest|= \",len(Ytest),\"\\tperf= \",perf[-1])\n",
    "\n",
    "# On transforme la liste en array numpy pour avoir les fonctions statistiques:\n",
    "perf = np.array(perf)\n",
    "print(f'\\nRésultat global avec crossval :\\tmoyenne= {perf.mean():.3f}\\técart-type= {perf.std():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction en fonction de Installs et Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des labels\n",
    "label_rating_set = gpsdf['Rating'].to_numpy()\n",
    "\n",
    "# Récupération des descriptions\n",
    "desc_installs_size_set = ut.normalisation(gpsdf[['Installs', 'Size']].to_numpy()) # Installs x Reviews\n",
    "\n",
    "# Création d'un classifieur k-means allant étudier la situation\n",
    "kmeans_installs_size = ClassifierKmeans(50)\n",
    "\n",
    "# Entrainement du classifieur\n",
    "kmeans_installs_size.train(desc_installs_size_set, label_rating_set, epsilon=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir réalisé un premier apprentissage, on obtient les clusters suivants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.affiche_resultat(kmeans_installs_size.desc_set, kmeans_installs_size.liste_centroides, kmeans_installs_size.matrice_affectation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant 50 clusters différents, on obtient les résultats de précision suivants grâce à la validation croisée sur 10 itérations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des données (Installs X Size => Rating)\n",
    "X = ut.normalisation(gpsdf[['Installs', 'Size']].to_numpy())\n",
    "Y = gpsdf['Rating'].to_numpy()\n",
    "\n",
    "niter = 10\n",
    "nbCentroides = 50\n",
    "perf = []\n",
    "# Utilisation de la validation croisée\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = ut.crossval(X, Y, niter, i)\n",
    "    cl = ClassifierKmeans(nbCentroides)\n",
    "    cl.train(Xapp, Yapp)\n",
    "    perf.append(cl.accuracy(Xtest, Ytest))\n",
    "    print(\"Apprentissage \",i+1,\":\\t\",\" |Yapp|= \",len(Yapp),\" |Ytest|= \",len(Ytest),\"\\tperf= \",perf[-1])\n",
    "\n",
    "# On transforme la liste en array numpy pour avoir les fonctions statistiques:\n",
    "perf = np.array(perf)\n",
    "print(f'\\nRésultat global avec crossval :\\tmoyenne= {perf.mean():.3f}\\técart-type= {perf.std():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction en fonction de Size et Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des labels\n",
    "label_rating_set = gpsdf['Rating'].to_numpy()\n",
    "\n",
    "# Récupération des descriptions\n",
    "desc_size_reviews_set = ut.normalisation(gpsdf[['Size', 'Reviews']].to_numpy()) # Installs x Reviews\n",
    "\n",
    "# Création d'un classifieur k-means allant étudier la situation\n",
    "kmeans_size_reviews = ClassifierKmeans(50)\n",
    "\n",
    "# Entrainement du classifieur\n",
    "kmeans_size_reviews.train(desc_size_reviews_set, label_rating_set, epsilon=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir réalisé un premier apprentissage, on obtient les clusters suivants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.affiche_resultat(kmeans_size_reviews.desc_set, kmeans_size_reviews.liste_centroides, kmeans_size_reviews.matrice_affectation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant 50 clusters différents, on obtient les résultats de précision suivants grâce à la validation croisée sur 10 itérations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des données (Size x Reviews => Rating)\n",
    "X = ut.normalisation(gpsdf[['Size', 'Reviews']].to_numpy())\n",
    "Y = gpsdf['Rating'].to_numpy()\n",
    "\n",
    "niter = 10\n",
    "nbCentroides = 50\n",
    "perf = []\n",
    "# Utilisation de la validation croisée\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = ut.crossval(X, Y, niter, i)\n",
    "    cl = ClassifierKmeans(nbCentroides)\n",
    "    cl.train(Xapp, Yapp)\n",
    "    perf.append(cl.accuracy(Xtest, Ytest))\n",
    "    print(\"Apprentissage \",i+1,\":\\t\",\" |Yapp|= \",len(Yapp),\" |Ytest|= \",len(Ytest),\"\\tperf= \",perf[-1])\n",
    "\n",
    "# On transforme la liste en array numpy pour avoir les fonctions statistiques:\n",
    "perf = np.array(perf)\n",
    "print(f'\\nRésultat global avec crossval :\\tmoyenne= {perf.mean():.3f}\\técart-type= {perf.std():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Analyse des premiers résultats\n",
    "\n",
    "Après avoir réalisé une première série d'analyses, on en arrive à une première conclusion : on ne peut pas prédire la popularité d'une application en fonction de sa note (Rating) puisque ces premiers résultats montrent une précision grâce à la validation croisée d'environ 12% en moyenne, ce qui n'est pas suffisant.\n",
    "\n",
    "On va donc se concentrer uniquement sur le nombre de téléchargements de l'application.\n",
    "\n",
    "Il y a un trop grand nombre d'applications avec un faible nombre de téléchargements mais à la note élevée. Il faudrait donc réaliser une sélection dans la base de données et conserver uniquement les applications les plus populaires. On considère qu'une application n'est populaire que si elle remplit les critères suivants :\n",
    "- un nombre de téléchargements supérieur ou égal à 1 million\n",
    "- une note moyenne donnée par les utilisateurs de l'application supérieure ou égale à 4\n",
    "\n",
    "On réalise alors cette sélection sur la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère l'indice des applications satisfaisant les conditions citées au-dessus\n",
    "newgpsdf = gpsdf[gpsdf['Rating'] >= 4.] # Note supérieure ou égale à 4\n",
    "newgpsdf = newgpsdf[newgpsdf['Installs'] >= 10000000] # Nombre de téléchargements supérieur ou égal à 1.000.000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre d'exemples restant dans cette base de données est de :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newgpsdf.shape[0], \"exemples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Prédiction du nombre de téléchargements (Installs) dans la nouvelle base de données\n",
    "\n",
    "Ayant désormais une base de données plus adaptée à nos recherches, on effectue une nouvelle fois une série de tests afin de mettre en avant s'il existe un moyen de prédire le nombre de téléchargements d'une application à travers une série de facteurs.\n",
    "\n",
    "### Prédiction en fonction de Rating et Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des labels\n",
    "label_installs_set = newgpsdf['Installs'].to_numpy()\n",
    "\n",
    "# Récupération des descriptions\n",
    "desc_rating_reviews_set = ut.normalisation(newgpsdf[['Rating', 'Reviews']].to_numpy()) # Rating x Reviews\n",
    "\n",
    "# Création d'un classifieur k-means allant étudier la situation\n",
    "kmeans_rating_reviews = ClassifierKmeans(30)\n",
    "\n",
    "# Entrainement du classifieur\n",
    "kmeans_rating_reviews.train(desc_rating_reviews_set, label_installs_set, epsilon=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir réalisé un premier apprentissage, on obtient les clusters suivants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.affiche_resultat(kmeans_rating_reviews.desc_set, kmeans_rating_reviews.liste_centroides, kmeans_rating_reviews.matrice_affectation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant **(len(np.unique(Y)) * 2)** centroides différents, on obtient les résultats de précision suivants grâce à la validation croisée sur 10 itérations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des données (Rating x Reviews => Installs)\n",
    "X = ut.normalisation(newgpsdf[['Rating', 'Reviews']].to_numpy())\n",
    "Y = newgpsdf['Installs'].to_numpy()\n",
    "\n",
    "niter = 10\n",
    "nbCentroides = len(np.unique(Y)) * 2\n",
    "perf = []\n",
    "\n",
    "# Utilisation de la validation croisée\n",
    "for i in range(niter) :\n",
    "    Xapp,Yapp,Xtest,Ytest = ut.crossval(X, Y, niter, i)\n",
    "    cl = ClassifierKmeans(nbCentroides)\n",
    "    cl.train(Xapp, Yapp)\n",
    "    perf.append(cl.accuracy(Xtest, Ytest))\n",
    "    print(\"Apprentissage \",i+1,\":\\t\",\" |Yapp|= \",len(Yapp),\" |Ytest|= \",len(Ytest),\"\\tperf= \",perf[-1])\n",
    "\n",
    "# On transforme la liste en array numpy pour avoir les fonctions statistiques:\n",
    "perf = np.array(perf)\n",
    "print(f'\\nRésultat global avec crossval :\\tmoyenne= {perf.mean():.3f}\\técart-type= {perf.std():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction en fonction de Rating et Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des labels\n",
    "label_installs_set = newgpsdf['Installs'].to_numpy()\n",
    "\n",
    "# Récupération des descriptions\n",
    "desc_rating_size_set = ut.normalisation(newgpsdf[['Rating', 'Size']].to_numpy()) # Rating x Reviews\n",
    "\n",
    "# Création d'un classifieur k-means allant étudier la situation\n",
    "kmeans_rating_size = ClassifierKmeans(30)\n",
    "\n",
    "# Entrainement du classifieur\n",
    "kmeans_rating_size.train(desc_rating_size_set, label_installs_set, epsilon=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir réalisé un premier apprentissage, on obtient les clusters suivants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.affiche_resultat(kmeans_rating_size.desc_set, kmeans_rating_size.liste_centroides, kmeans_rating_size.matrice_affectation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant **(len(np.unique(Y)) * 2)** centroides différents, on obtient les résultats de précision suivants grâce à la validation croisée sur 10 itérations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des données (Rating x Size => Installs)\n",
    "X = ut.normalisation(newgpsdf[['Rating', 'Size']].to_numpy())\n",
    "Y = newgpsdf['Installs'].to_numpy()\n",
    "\n",
    "niter = 10\n",
    "nbCentroides = len(np.unique(Y)) * 2\n",
    "perf = []\n",
    "\n",
    "# Utilisation de la validation croisée\n",
    "for i in range(niter) :\n",
    "    Xapp,Yapp,Xtest,Ytest = ut.crossval(X, Y, niter, i)\n",
    "    cl = ClassifierKmeans(nbCentroides)\n",
    "    cl.train(Xapp, Yapp)\n",
    "    perf.append(cl.accuracy(Xtest, Ytest))\n",
    "    print(\"Apprentissage \",i+1,\":\\t\",\" |Yapp|= \",len(Yapp),\" |Ytest|= \",len(Ytest),\"\\tperf= \",perf[-1])\n",
    "\n",
    "# On transforme la liste en array numpy pour avoir les fonctions statistiques:\n",
    "perf = np.array(perf)\n",
    "print(f'\\nRésultat global avec crossval :\\tmoyenne= {perf.mean():.3f}\\técart-type= {perf.std():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction en fonction de Reviews et Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des labels\n",
    "label_installs_set = newgpsdf['Installs'].to_numpy()\n",
    "\n",
    "# Récupération des descriptions\n",
    "desc_reviews_size_set = ut.normalisation(newgpsdf[['Reviews', 'Size']].to_numpy()) # Rating x Reviews\n",
    "\n",
    "# Création d'un classifieur k-means allant étudier la situation\n",
    "kmeans_reviews_size = ClassifierKmeans(30)\n",
    "\n",
    "# Entrainement du classifieur\n",
    "kmeans_reviews_size.train(desc_reviews_size_set, label_installs_set, epsilon=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir réalisé un premier apprentissage, on obtient les clusters suivants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.affiche_resultat(kmeans_reviews_size.desc_set, kmeans_reviews_size.liste_centroides, kmeans_reviews_size.matrice_affectation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant **(len(np.unique(Y)) * 2)** centroides différents, on obtient les résultats de précision suivants grâce à la validation croisée sur 10 itérations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Récupération des données (Reviews x Size => Installs)\n",
    "X = ut.normalisation(newgpsdf[['Reviews', 'Size']].to_numpy())\n",
    "Y = newgpsdf['Installs'].to_numpy()\n",
    "\n",
    "niter = 10\n",
    "nbCentroides = len(np.unique(Y)) * 2\n",
    "perf = []\n",
    "\n",
    "# Utilisation de la validation croisée\n",
    "for i in range(niter) :\n",
    "    Xapp,Yapp,Xtest,Ytest = ut.crossval(X, Y, niter, i)\n",
    "    cl = ClassifierKmeans(nbCentroides)\n",
    "    cl.train(Xapp, Yapp)\n",
    "    perf.append(cl.accuracy(Xtest, Ytest))\n",
    "    print(\"Apprentissage \",i+1,\":\\t\",\" |Yapp|= \",len(Yapp),\" |Ytest|= \",len(Ytest),\"\\tperf= \",perf[-1])\n",
    "\n",
    "# On transforme la liste en array numpy pour avoir les fonctions statistiques:\n",
    "perf = np.array(perf)\n",
    "print(f'\\nRésultat global avec crossval :\\tmoyenne= {perf.mean():.3f}\\técart-type= {perf.std():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction en fonction de Rating, Size et Reviews\n",
    "\n",
    "On essaye maintenant d'utiliser les 3 facteurs précédents en meme temps.\n",
    "\n",
    "En utilisant **(len(np.unique(Y)) * 2)** centroides différents, on obtient les résultats de précision suivants grâce à la validation croisée sur 10 itérations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des données (Reviews x Rating x Size => Installs)\n",
    "X = ut.normalisation(newgpsdf[['Reviews', 'Rating', 'Size']].to_numpy())\n",
    "Y = newgpsdf['Installs'].to_numpy()\n",
    "\n",
    "niter = 10\n",
    "nbCentroides = len(np.unique(Y)) * 2\n",
    "perf = []\n",
    "\n",
    "# Utilisation de la validation croisée\n",
    "for i in range(niter) :\n",
    "    Xapp,Yapp,Xtest,Ytest = ut.crossval(X, Y, niter, i)\n",
    "    cl = ClassifierKmeans(nbCentroides)\n",
    "    cl.train(Xapp, Yapp)\n",
    "    perf.append(cl.accuracy(Xtest, Ytest))\n",
    "    print(\"Apprentissage \",i+1,\":\\t\",\" |Yapp|= \",len(Yapp),\" |Ytest|= \",len(Ytest),\"\\tperf= \",perf[-1])\n",
    "\n",
    "# On transforme la liste en array numpy pour avoir les fonctions statistiques:\n",
    "perf = np.array(perf)\n",
    "print(f'\\nRésultat global avec crossval :\\tmoyenne= {perf.mean():.3f}\\técart-type= {perf.std():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Utilisation du meilleur modèle trouvé avec un nombre de centroides différent\n",
    "\n",
    "Le modèle ayant présenté les meilleurs résultats lors de nos résultats est le modèle réalisant la prédiction du nombre d'installations d'une application en fonction de son nombre d'avis et sa note dans la base de données modifiée (précision moyenne de 74.4%).\n",
    "\n",
    "Nous allons donc réaliser de nouveaux apprentissages sur ce modèle en utilisant à chaque fois un nombre de centroides différents. A chaque itération, on affichera la moyenne de précision l'écart-type en fonction du nombre de centroides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des données (Rating x Reviews => Installs)\n",
    "X = ut.normalisation(newgpsdf[['Rating', 'Reviews']].to_numpy())\n",
    "Y = newgpsdf['Installs'].to_numpy()\n",
    "\n",
    "# Parametres utilisés (on incrementera le nombre de centroides de 5 à chaque fois sur l'intervalle 5 et 50)\n",
    "# On utilise toujours 10 de crossval pour les résultats\n",
    "nbCentroides = 5\n",
    "niter = 10\n",
    "\n",
    "# Utilisation de la validation croisée\n",
    "while (nbCentroides <= 50) :\n",
    "    \n",
    "    # Réalisation des tests\n",
    "    perf = []\n",
    "    for i in range(niter) :\n",
    "        Xapp,Yapp,Xtest,Ytest = ut.crossval(X, Y, niter, i)\n",
    "        cl = ClassifierKmeans(nbCentroides)\n",
    "        cl.train(Xapp, Yapp)\n",
    "        perf.append(cl.accuracy(Xtest, Ytest))\n",
    "    \n",
    "    # Affichage et incrémentation\n",
    "    perf = np.array(perf)\n",
    "    print(f'Résultat global avec {nbCentroides} centroides :\\tmoyenne= {perf.mean():.3f}\\técart-type= {perf.std():.3f}')\n",
    "    nbCentroides += 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Nouvel apprentissage en fonction du caractère payant ou non de l'application\n",
    "\n",
    "On récupère les applications gratuites et les applications payantes de la base de données newgpsdf, soit les applications payantes parmi les applications ayant plus d'un million de téléchargements et une note moyenne supérieure à 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère les applications gratuites de newgpsdf\n",
    "newgpsdf_free = newgpsdf[newgpsdf['Type'] == 0]\n",
    "print(\"Le nombre d'applications gratuites est de \" + str(newgpsdf_free.shape[0]) + \".\")\n",
    "\n",
    "# On récupère les applications payantes de newgpsdf\n",
    "newgpsdf_paid = newgpsdf[newgpsdf['Type'] == 1]\n",
    "print(\"Le nombre d'applications payantes est de \" + str(newgpsdf_paid.shape[0]) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque alors directement qu'il n'existe qu'un seul exemple dans la base de données représentant une application payante au nombre de téléchargements supérieurs à un million et à la note moyenne supérieure à 4.<br/>Cela rend donc impossible donc la réalisation de tout apprentissage et prédiction sur les applications payantes.\n",
    "\n",
    "Le nombre d'exemples représentant des applications gratuites étant le même que le nombre d'exemples dans la base de données d'origine, à 1 près, on en conclut que l'apprentissage et la prédiction peut être réalisée sans problème."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 6 - Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les premiers résultats ont permis de mettre en avant qu'il était envisageable qu'un modèle utilisant une combinaison de facteurs précis puisse permettre de prédire la popularité d'une application. La popularité était représentée soit par le nombre de téléchargements, soit par la note moyenne de l'application.\n",
    "\n",
    "Les modèles qu'on a décidé d'utiliser consistent à prédire le nombre d'installations d'une application en fonction de la combinaison de facteurs choisie, avec une précision moyenne de 22%. Prédire la note moyenne de l'application paraissait impossible puisque la précision moyenne des modèles testés réalisant cette prédiction était proche de 12%.\n",
    "\n",
    "Les premiers résultats n'étant pas satisfaisants, on a donc réalisé une sélection au sein des exemples de la base de données afin de ne conserver que les applications populaires.\n",
    "\n",
    "On a considéré qu'une application est considérée comme populaire que si son nombre de téléchargements était supérieur à 1 million et sa note moyenne supérieure à 4. On a choisi ces critères-là puisqu' on suppose qu'une personne sur PlayStore sera intéressée par une application remplissant ces deux critères.\n",
    "\n",
    "Par la suite, on a utilisé les modèles de prédiction du nombre d'installations avec la nouvelle base de données. Les résultats obtenus étaient nettement supérieurs à ceux obtenus précédemment. La précision moyenne des modèles est passé de 22% à 70%. Il s'agit donc importante amélioration.\n",
    "\n",
    "Le meilleur modèle est celui réalisant la prédiction du nombre d'installations en fonction du nombre d'avis et de la note moyenne de l'application, avec une précision moyenne de 75%. Il est donc possible de prédire le nombre d'installations d'une application populaire 3 fois sur 4.\n",
    "\n",
    "On a ensuite cherché à savoir si le fait qu'une application soit payante ou non puisse influencer la prédiction du nombre d'installations. Il se trouve que parmi les applications qu'on a jugées populaires, seulement une seule est payante. On en conclut que notre modèle ne permet pas de prédire le nombre d'installations des applications populaires payantes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "name": "python386jvsc74a57bd09c6bd1c1dcf038e17a85a01199468631d2d406fade8f6cc5eea24dc919f509a1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
